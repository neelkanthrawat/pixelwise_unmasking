{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e465f260",
   "metadata": {},
   "source": [
    "tasks to do:\n",
    "Given/ What we already have:\n",
    "\n",
    "0. We have the code to generate the image in a go. \n",
    "Tasks to do:\n",
    "1. YES: LATENT DISTRIBUTION IS INDEED FACTORED NORMAL DISTRIBUTION FOR EACH ZI ~~Check how the latent distribution is defined? For our present use case, we need to define the latent distribution for indiviudual pixels I think.~~ \n",
    "2. Add the procedural pixel selection/ unmasking thing. The idea is:\n",
    "    * Generate all the pixels, accept only a few of them and then reject the other ones and then resample the remaining portion of the image again.\n",
    "\n",
    "\n",
    "## some notes:\n",
    "\n",
    "1. In the current architecture by the previous student, the dimension of the latent space is same as that of the original data space.\n",
    "    * The current code also something like: `torch.linalg.slogdet` and maybe that is suppose to be square? I need to look into this thingy and generalise the code. the current architecture is extremely restrictive\n",
    "        * Task to do: fix this -ish. Make the code as general as possible. and then  for the use case, one can set the latent dimension to be same as the input dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc2675ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\ntasks to do:\\n\\n1. re-factor the code\\n2. run the code for a very simple problem instance.\\n3. add the pipeline to resample everything and move on.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "tasks to do:\n",
    "\n",
    "1. re-factor the code\n",
    "2. run the code for a very simple problem instance.\n",
    "3. add the pipeline to resample everything and move on.\n",
    "'''\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an idea that I can think of is:\n",
    "# conditional generation: the idea is that maybe some sort of conditional generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc09e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root (one directory up from notebooks)\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root (one directory up from notebooks)\n",
    "sys.path.append(os.path.abspath('..'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f844e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# model related\n",
    "from models.fff_model import resnet, MLP, brazy_encoder, brazy_decoder, cond_conv_encoder, cond_conv_decoder, FreeFormFlow, condFreeFormFlow, ImprovedCNN\n",
    "from models.architectures_fff import CondConfig, get_encoder_and_decoder\n",
    "\n",
    "# model training related\n",
    "from models.feature_extractor_creator import train_feature_extractor\n",
    "\n",
    "#data related\n",
    "from data.dataloaders_related import get_masked_mnist_dataloaders\n",
    "\n",
    "# plotting related\n",
    "from utils.plotting import  five_samples_same_model_during_training\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# trainer\n",
    "from training.trainer import train_model_mnist, test_model\n",
    "\n",
    "# \n",
    "import tqdm\n",
    "from typing import Literal\n",
    "from dataclasses import dataclass\n",
    "from typing import Literal, Union, Tuple, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd6be349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device= 'cpu'#\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "pixelwidth = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82418458",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_cfg = CondConfig(\n",
    "    fff_c_small=32,\n",
    "    fff_f1_dim=512, \n",
    "    fff_f2_dim=1024, \n",
    "    fff_input_dim=28*28,\n",
    "    fff_output_dim=28*28, \n",
    "    fff_batchnorm=True, \n",
    "    fff_third_conv=False, \n",
    "    fff_cond_dim=10,\n",
    "    fff_dropout=0.0,\n",
    ")\n",
    "\n",
    "# get conditional encoder and conditional decoder\n",
    "encoder, decoder = get_encoder_and_decoder('conditional', cond_cfg, device=device)\n",
    "\n",
    "# get the model\n",
    "fours_fff =  FreeFormFlow(encoder, decoder, device=device, data_dims=pixelwidth**2).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd721cd",
   "metadata": {},
   "source": [
    "### Training some feature extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f139f350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "batch_size_feat_extractor = 63\n",
    "learning_rate_feat_extractor= 0.001\n",
    "epochs_feat_extractor = 5\n",
    "\n",
    "#Dataloaders\n",
    "train_loader, test_loader = get_masked_mnist_dataloaders(\n",
    "                            batchsize=batch_size_feat_extractor, \n",
    "                            pixelwidth=28, \n",
    "                            digit=4\n",
    "                            ) \n",
    "\n",
    "# Train feature extractor model\n",
    "fid_feature_extractor = ... # I need to write a newer train_feature_extractor it seems\n",
    "#fid_feature_extractor = train_feature_extractor(\n",
    "#     ImprovedCNN, train_loader, device, learning_rate_feat_extractor, epochs_feat_extractor\n",
    "# )\n",
    "\n",
    "# evaluate the model on the test data\n",
    "... # need to write a new test_model() but this new type of dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
